Got it. Welcome to the Hive clubâ€”where SQL meets big data, and your MapReduce output finally gets to party.

Letâ€™s go step-by-step and get your data Hive-ready. You already have:

lua
Copy
Edit
File: output/output.txt
Contents: (tab-separated)
userId,bookId    score
ğŸ STEP-BY-STEP: Load Hadoop Output into Hive
âœ… Step 1: Move file to HDFS
Hive doesn't read local files directlyâ€”you need it in HDFS.

bash
Copy
Edit
hdfs dfs -mkdir -p /user/hive/warehouse/book_interactions
hdfs dfs -put output/output.txt /user/hive/warehouse/book_interactions/
ğŸ“ If output.txt is already in HDFS, just skip this and check the path with:

bash
Copy
Edit
hdfs dfs -ls /user/hive/warehouse/book_interactions
âœ… Step 2: Start Hive CLI
bash
Copy
Edit
hive
âœ… Step 3: Create External Table in Hive
Youâ€™re telling Hive:

This is tab-delimited

Fields are userId, bookId, score

Data already exists in HDFS, donâ€™t move it

sql
Copy
Edit
CREATE EXTERNAL TABLE IF NOT EXISTS book_interactions (
    userId STRING,
    bookId STRING,
    score INT
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY '\t'
LOCATION '/user/hive/warehouse/book_interactions';
âœ… Step 4: Query Examples
ğŸ” Get all data
sql
Copy
Edit
SELECT * FROM book_interactions LIMIT 10;
ğŸ“š Top 5 books overall (by total score)
sql
Copy
Edit
SELECT bookId, SUM(score) AS total_score
FROM book_interactions
GROUP BY bookId
ORDER BY total_score DESC
LIMIT 5;
ğŸ‘¤ Top books for a specific user
sql
Copy
Edit
SELECT bookId, score
FROM book_interactions
WHERE userId = '68289a3d84bc5a83ae986872'
ORDER BY score DESC;
ğŸ’¡ Tips
You can create views or join with other tables (like a books table with titles/genres).

Hive is read-onlyâ€”donâ€™t try to UPDATE, use INSERT OVERWRITE instead if needed.

Since your file is clean, you donâ€™t need SerDes or complex formats.

